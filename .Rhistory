sort.noun
library( wordcloud )
library( wordcloud2 )
library( KoNLP )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd('D:/WorkR ')
text <- readLines( 'ex_10-1.txt','0x_10-2.txt','ex_10-3.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun <- sort.noun[ -1,-2 ]
sort.noun
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
library( wordcloud )
library( wordcloud2 )
library( KoNLP )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd('D:/WorkR ')
text <- readLines( 'ex_10-1.txt','0x_10-2.txt','ex_10-3.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun <- sort.noun[ -1, ]
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun <- sort.noun[ -1, ]
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun <- sort.noun[ -1, ]
noun2 <- noun2[nchar(noun2) = 1 ]
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
wordcount <- table(noun2)
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
sort.noun
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun <- sort.noun[ -1, ]
noun2 <- noun2[nchar(noun2) = 1 ]
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
noun2 <- gsub(' ', '', noun2)
noun2 <- gsub('한', '', noun2)
wordcount <- table(noun2)
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
sort.noun
noun2
wordcount
noun2
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun
noun2
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:10]
sort.noun
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table( noun2 )
sort.noun <- sort( wordcount, decreasing = T) [1:20]
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
sort.noun
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
noun2 <- noun2[nchar(noun2) = 1 ]
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
noun2 <- gsub(' ', '', noun2)
noun2 <- gsub('일', '', noun2)
noun2 <- gsub('내', '', noun2)
noun2 <- gsub('때', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('그것', '', noun2)
noun2 <- gsub('년', '', noun2)
noun2 <- gsub('말', '', noun2)
noun2 <- gsub('그', '', noun2)
wordcount <- table(noun2)
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
noun2 <- noun2[nchar(noun2) > 1 ]
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
noun2 <- gsub(' ', '', noun2)
noun2 <- gsub('일', '', noun2)
noun2 <- gsub('내', '', noun2)
noun2 <- gsub('때', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('그것', '', noun2)
noun2 <- gsub('년', '', noun2)
noun2 <- gsub('말', '', noun2)
noun2 <- gsub('그', '', noun2)
wordcount <- table(noun2)
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-5.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )    # 사전에 추가 한 후 테이블 만들기 전 벡터화
noun2 <- noun2[nchar(noun2) > 1 ]    # 불필요한 단어 삭제
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
noun2 <- gsub(' ', '', noun2)
noun2 <- gsub('일', '', noun2)
noun2 <- gsub('내', '', noun2)
noun2 <- gsub('때', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('그것', '', noun2)
noun2 <- gsub('년', '', noun2)
noun2 <- gsub('말', '', noun2)
noun2 <- gsub('그', '', noun2)
wordcount <- table(noun2)          # 테이블화
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )    # 사전에 추가 한 후 테이블 만들기 전 벡터화
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]
noun2 <- noun2[nchar(noun2) > 1 ]    # 불필요한 단어 삭제
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
noun2 <- gsub(' ', '', noun2)
noun2 <- gsub('일', '', noun2)
noun2 <- gsub('내', '', noun2)
noun2 <- gsub('때', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('그것', '', noun2)
noun2 <- gsub('년', '', noun2)
noun2 <- gsub('말', '', noun2)
noun2 <- gsub('그', '', noun2)
wordcount <- table(noun2)          # 테이블화
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-5.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
noun2
wordcount <- table(noun2)
wordcount
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]
sort.noun
sort.noun <- sort.noun[ -1 ]
sort.noun
setwd('D:/WorkR ')
text <- readLines( 'ex_10-5.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
wordcount <- table(noun2)
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]
sort.noun <- sort.noun[ -1 ]
noun2 <- noun2[nchar(noun2) > 1 ]    # 불필요한 단어 삭제
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('저', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('한', '', noun2)
noun2 <- gsub('앞', '', noun2)
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-5.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )
#wordcount <- table(noun2)
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]
sort.noun <- sort.noun[ -1 ]
noun2 <- noun2[nchar(noun2) > 1 ]    # 불필요한 단어 삭제
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('저', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('한', '', noun2)
noun2 <- gsub('앞', '', noun2)
wordcount <- table(noun2)
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-4.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun )    # 사전에 추가 한 후 테이블 만들기 전 벡터화
noun2 <- noun2[nchar(noun2) > 1 ]    # 불필요한 단어 삭제
noun2 <- gsub('것', '', noun2)
noun2 <- gsub('나', '', noun2)
noun2 <- gsub(' ', '', noun2)
noun2 <- gsub('일', '', noun2)
noun2 <- gsub('내', '', noun2)
noun2 <- gsub('때', '', noun2)
noun2 <- gsub('수', '', noun2)
noun2 <- gsub('들', '', noun2)
noun2 <- gsub('그것', '', noun2)
noun2 <- gsub('년', '', noun2)
noun2 <- gsub('말', '', noun2)
noun2 <- gsub('그', '', noun2)
wordcount <- table(noun2)          # 테이블화 # 테이블 화 하면 단어당 갯수정리
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
setwd('D:/WorkR ')
text <- readLines( 'ex_10-1.txt','0x_10-2.txt','ex_10-3.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
pal2
library( wordcloud )
library( wordcloud2 )
library( KoNLP )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd('D:/WorkR ')
text <- readLines( 'mis_document.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')                    # 색상 팔레트 생성. 나중에 워드클라우드함수에서 사용
noun <- sapply( text, extractNoun, USE.NAMES = F ) # 명사추출 # 행이름을 안쓰겠다
noun
noun2 <- unlist( noun ) # list 를 vector 로 변환 # noun은 chr로써 문자형인데 table을 만들기 위해서 vector 로 변환
wordcount <- table( noun2 )
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]
sort.noun <- sort.noun[ -1 ]                              # 첫번째는 띄어쓰기라서 뺸건가 ?
barplot( sort.noun, names.arg = names (sort.noun ),
col = 'steelblue', main = ' 빈도수높은단어 ',
ylab = ' 단어 빈도수 ')
df <- as.data.frame( sort.noun)
df
ggplot ( df, aes ( x = df$noun2 , y=df$Freq ) ) +
geom_bar( stat = 'identity',
width = 0.7 ,
fill = 'steelblue') +
ggtitle( ' 빈도수 높은 단어 ') +
theme ( plot.title = element_text( size = 25,
face = 'bold',
colour = 'steelblue',
hjust = 0,
vjust = 1)) +
labs( x = '명사', y = '단어빈도수') +
geom_text( aes ( label = df$Freq), hjust = -0.3) +
coord_flip()
buildDictionary
text
library( wordcloud )
library( wordcloud2 )
library( KoNLP )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd('D:/WorkR ')
text <- readLines( 'mis_document.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')                    # 색상 팔레트 생성. 나중에 워드클라우드함수에서 사용
noun <- sapply( text, extractNoun, USE.NAMES = F ) # 명사추출 # 행이름을 안쓰겠다 # 각라인에서 명사단어만 가져오기
library( wordcloud )
library( wordcloud2 )
library( KoNLP )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd('D:/WorkR ')
text <- readLines( 'mis_document.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun ) # 색출한 명사 모으 # list 를 vector 로 변환 # noun은 chr로써 문자형인데 table을 만들기 위해서 vector 로 변환
wordcount <- table( noun2 )  # 테이블은 단어 출현 수를 나타내기 위해서
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]   # sort는 정럴 # 내림차순으로 # 10개 까지
sort.noun <- sort.noun[ -1 ]                              # 첫번째는 띄어쓰기라서 빼라. # 2개 빼고 싶으면 c(-1, -2 )
wordcloud( names ( wordcount),       # 단어
freq = wordcount,          # 단어빈도
scale = c( 6, 0.7),      # 단어폰트크기(최대,최소)
min.freq = 2,          # 단어최소빈도
random.order = F,      # 단어출력위치
rot.per = .1,         # 90도 회전단어비율 .1은 10% -> 10%단어는 회전해라
colors = pal2)           # 단어색
library( wordcloud )
library( wordcloud2 )
library( KoNLP )
library( RColorBrewer )
library( dplyr )
library( ggplot2 )
setwd('D:/WorkR ')
text <- readLines( 'mis_document.txt', encoding = 'UTF-8')
text
buildDictionary( ext_dic = 'woorimalsam')
pal2 <- brewer.pal( 8, 'Dark2')
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist( noun ) # 색출한 명사 모으 # list 를 vector 로 변환 # noun은 chr로써 문자형인데 table을 만들기 위해서 vector 로 변환
wordcount <- table( noun2 )  # 테이블은 단어 출현 수를 나타내기 위해서
sort.noun <- sort( wordcount,decreasing = T) [ 1:10 ]   # sort는 정럴 # 내림차순으로 # 10개 까지
sort.noun <- sort.noun[ -1 ]                              # 첫번째는 띄어쓰기라서 빼라. # 2개 빼고 싶으면 c(-1, -2 )
buildDictionary( ext_dic = 'woorimalsam',
user_dic = data.frame('정치', 'ncn'),        #우리말씅에 삭제할 단어 넣는다 ncn은 명사 ? ( 자료에는 있는데 사전에는 없는것을 사전에 넣기 )
replace_usr_dic = T)                      # 추가하기
noun <- sapply(text, extractNoun, USE.NAMES = F )          # 사전에 단어 넣었으니 다시 단어 추출
noun <- unlist(noun)                                       # 색출한 명사 모으기
noun2 <- noun2[ nchar(noun2) = 1 ]      # 1글자 짜리 삭제
noun2 <- gsub('하지', '', noun2)        # 하지를 ' ' 로 바꾸라 -> = 삭제하라
noun2 <- gsub('때문', '', noun2)
wordcount <- table(noun2)               # 빈도
wordcloud( names ( wordcount),
freq = wordcount,
scale = c( 6, 0.7),
min.freq = 2,
random.order = F,
rot.per = .1,
colors = pal2)
